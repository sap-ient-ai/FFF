{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Full Tree\n",
    "\n",
    "ðŸ”´ WiP\n",
    "\n",
    "(Currently it trains poorly, so there's some error)\n",
    "\n",
    "The first paper version suggests using the WHOLE tree during training, and ONLY\n",
    "during inference do we choose a single path thru the tree.\n",
    "\n",
    "Notice the `p` and `1-p` in the diagram.\n",
    "\n",
    "So let's do it!\n",
    "\n",
    "If we just train the whole tree for each input item, and use the whole tree\n",
    "for inference, we get FF-level accuracy:\n",
    "```\n",
    "Accuracy of the network over test images: 97.370 %\n",
    "```\n",
    "\n",
    "But that's distributing the computation over the whole tree.\n",
    "Every node is pulling weight.\n",
    "\n",
    "So we introduce a penalty that, for a given input, pushes each node\n",
    "to channel its work thru either one branch or t'other.\n",
    "\n",
    "i.e. an even split (corresponding to a p of 0.5) will be penalized.\n",
    "\n",
    "This pushes the network to \"harden\" the decisions. It pushes it to use\n",
    "p values close to 0 or close to 1.\n",
    "\n",
    "And then when we do inference, we just pick the winning path, based\n",
    "on the assunmption that THAT path is doing the bulk of the work.\n",
    "\n",
    "Simultaneously it's pushing the y-projections to accomodate this\n",
    "\"hardened\" decision-process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¹ Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBATCH, NBATCH_TEST = 128, -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def load_MNIST():\n",
    "    # Transformations\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    # MNIST dataset\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Data loaders\n",
    "    nTest = NBATCH_TEST if NBATCH_TEST > 0 else len(testset)\n",
    "    trainloader = DataLoader(trainset, batch_size=NBATCH, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=nTest, shuffle=False)\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "# trainloader, testloader = load_MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # https://github.com/microsoft/debugpy/issues/1166\n",
    "    # ^ set nWorkers=1 to avoid this\n",
    "    def create_dataloader(train, nBatch, shuffle, nWorkers=1):\n",
    "        dataset = datasets.CIFAR10(\n",
    "            root='./data', train=train, download=True, transform=transform\n",
    "        )\n",
    "        return DataLoader(\n",
    "            dataset, batch_size=nBatch, shuffle=shuffle, num_workers=nWorkers\n",
    "        )\n",
    "\n",
    "    nTest = NBATCH_TEST if NBATCH_TEST > 0 else 1024\n",
    "    trainloader = create_dataloader(train=True, nBatch=NBATCH, shuffle=True)\n",
    "    testloader = create_dataloader(train=False, nBatch=1024, shuffle=False)\n",
    "\n",
    "    # Class labels\n",
    "    # classes = 'plane car bird cat deer dog frog horse ship truck'.split()\n",
    "    \n",
    "    return trainloader, testloader  #, classes\n",
    "\n",
    "# trainloader, testloader, classes = load_CIFAR10()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 9, 9, 8, 7, 0, 3, 5, 1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader, testloader = load_CIFAR10()\n",
    "\n",
    "batch = next(iter(trainloader))\n",
    "images, labels = batch\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¹ Test Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPOCH = 10\n",
    "EVERY_N = -1\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Test harness\n",
    "# We'll use this later\n",
    "# def orthogonality_loss(basis_vectors):\n",
    "#     # Compute pairwise dot products\n",
    "#     dot_products = torch.matmul(basis_vectors, basis_vectors.T)\n",
    "    \n",
    "#     # Zero out diagonal elements (self dot products)\n",
    "#     eye = torch.eye(dot_products.size(0)).to(dot_products.device)\n",
    "#     dot_products = dot_products * (1 - eye)\n",
    "    \n",
    "#     # Sum of squares of off-diagonal elements (which should be close to zero)\n",
    "#     loss = (dot_products ** 2).sum()\n",
    "#     return loss\n",
    "\n",
    "def train_and_test(net, dataloader):\n",
    "    trainloader, testloader = dataloader()\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=0.001) #, momentum=0.9)\n",
    "\n",
    "    # Training the network\n",
    "    for epoch in tqdm(range(NEPOCH)):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            if hasattr(net, 'loss'):\n",
    "                loss += net.loss()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % EVERY_N == EVERY_N - 1:  # print EVERY_N mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / EVERY_N:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Testing the network on the test data\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'[{epoch}] Accuracy of the network over test images: {100 * correct / total:.3f} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¹ use MNIST / FF to check it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [00:07<01:09,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Accuracy of the network over test images: 94.360 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [00:15<01:01,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Accuracy of the network over test images: 96.230 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:54,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Accuracy of the network over test images: 95.660 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:31<00:46,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Accuracy of the network over test images: 96.680 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:38<00:38,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Accuracy of the network over test images: 96.940 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:46<00:31,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Accuracy of the network over test images: 97.290 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:54<00:23,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Accuracy of the network over test images: 97.790 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:02<00:15,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Accuracy of the network over test images: 97.720 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:09<00:07,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] Accuracy of the network over test images: 97.560 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:16<00:00,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] Accuracy of the network over test images: 97.190 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network architecture\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features=28*28, out_features=500)\n",
    "        self.fc2 = torch.nn.Linear(in_features=500, out_features=10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        y_hat = self.fc2(torch.relu(self.fc1(x)))\n",
    "        # y_hat = self.fc2(self.fc1(x))\n",
    "        return y_hat\n",
    "    # def loss(self):\n",
    "    #     # Calculate orthogonality loss for each PiSlice layer\n",
    "    #     loss1 = orthogonality_loss(self.fc1.X) + orthogonality_loss(self.fc1.Y)\n",
    "    #     loss2 = orthogonality_loss(self.fc2.X) + orthogonality_loss(self.fc2.Y)\n",
    "    #     return loss1 + loss2\n",
    "\n",
    "train_and_test(Net(), dataloader=load_MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¸ FFF (with full-tree training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_STRAT = 'hyperspherical-shell'\n",
    "DEPTH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing training:\n",
      "loss: tensor(0.8769, grad_fn=<DivBackward0>)\n",
      "x.grad: tensor([[ 0.5445,  0.3354,  0.0194, -0.4392, -0.3159,  0.0731,  0.1984, -0.1836,\n",
      "         -0.2570, -0.1346],\n",
      "        [-0.1014, -0.0053, -0.1769,  0.0853,  0.0147, -0.0228, -0.0308,  0.0714,\n",
      "          0.0155,  0.1200]])\n",
      "Testing inference:\n",
      "loss: tensor(0., grad_fn=<DivBackward0>)\n",
      "y: tensor([[ 0.2908,  0.2454, -0.0561,  0.0537,  0.2312,  0.5513,  0.1997, -0.0057,\n",
      "          0.6941, -0.3613],\n",
      "        [-0.3041, -0.5350, -0.4723,  0.8024, -0.7482,  0.6833,  0.4123,  0.2983,\n",
      "         -0.5228,  0.9592]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "from typing import Optional\n",
    "from math import floor, log2, sqrt\n",
    "\n",
    "class FFF(torch.nn.Module):\n",
    "    def __init__(self, nIn: int, nOut: int, depth: Optional[int] = None):\n",
    "        super().__init__()\n",
    "        self.depth = depth or int(floor(log2(nIn)))  # depth is the number of decision boundaries\n",
    "        nNodes = 2 ** self.depth - 1\n",
    "\n",
    "        # each node \"holds\" a basis-vector in INPUT space (.X) and in OUTPUT space (.Y)\n",
    "\n",
    "        if INIT_STRAT == 'gaussian':\n",
    "            # This from orig authors; scaling looks off for self.Y\n",
    "            def create_basis_vectors_of(length, scaling):\n",
    "                return torch.nn.Parameter(torch.empty(nNodes, length).uniform_(-scaling, scaling))\n",
    "            self.X = create_basis_vectors_of(length=nIn, scaling=1/sqrt(nIn))\n",
    "            self.Y = create_basis_vectors_of(length=nOut, scaling=1/sqrt(self.depth + 1))\n",
    "\n",
    "        elif INIT_STRAT == 'hyperspherical-shell':\n",
    "            # Initialize vectors on INPUT/OUTPUT space unit hypersphere\n",
    "            #   (idea: basis vectors should be of unit length).\n",
    "            def create_random_unit_vectors_of(length):\n",
    "                weights = torch.randn(nNodes, length)  # Initialize weights randomly\n",
    "                weights = normalize(weights, p=2, dim=-1)  # L2-Normalize along the last dimension\n",
    "                return torch.nn.Parameter(weights)\n",
    "            self.X = create_random_unit_vectors_of(length=nIn)\n",
    "            self.Y = create_random_unit_vectors_of(length=nOut)\n",
    "\n",
    "            self.p_loss = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        nBatch, nOut, nNodes = x.shape[0], self.Y.shape[-1], 2 ** self.depth - 1\n",
    "        is_training = x.requires_grad\n",
    "    \n",
    "        # Walk the tree, assembling y piecemeal\n",
    "        y = torch.zeros((nBatch, nOut), dtype=torch.float, device=x.device, requires_grad=True)\n",
    "        \n",
    "        loss = torch.tensor(0.0, requires_grad=True)  # scalar tensor\n",
    "        # this would be wrong (1D tensor not same as scalar)\n",
    "        # loss = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "        if is_training:\n",
    "            def process_node(nodeIndex, p_in):\n",
    "                nonlocal y\n",
    "                if nodeIndex >= nNodes:\n",
    "                    return\n",
    "\n",
    "                # Project x onto the current node's INPUT basis vector\n",
    "                #   Î» = x DOT currNode.X\n",
    "                # (nBatch, nIn) nIn -> nBatch\n",
    "                Î» = torch.einsum('bi, i -> b', x, self.X[nodeIndex])\n",
    "\n",
    "                # Project this contribution into OUTPUT space:\n",
    "                #   y += Î» currNode.Y\n",
    "                # nBatch, nOut -> (nBatch, nOut)\n",
    "                # y += torch.einsum(\"b, j -> b j\", Î», self.Y[nodeIndex])\n",
    "                dy = torch.einsum('b,j -> bj', Î», self.Y[nodeIndex])\n",
    "                y = y + torch.einsum('b, bj -> bj', p_in, dy)\n",
    "\n",
    "                # ChatGPT says we can elide:\n",
    "                # y += torch.einsum(\"b, j, b -> b j\", p_in, self.Y[nodeIndex], Î»)\n",
    "\n",
    "                # e.g.\n",
    "                #   Î» = -10, so p ~ 0.0, so 1-p is HIGH\n",
    "                #   ... and we want to give HIGH weight to the LEFT node\n",
    "                #   ... so THAT gets the 1-p\n",
    "                p = torch.sigmoid(Î»)\n",
    "\n",
    "                # 0 if p is 0 or 1, 1 if p=0.5\n",
    "                nonlocal loss\n",
    "                loss = loss + torch.mean(4 * p * (1 - p), dim=0)\n",
    "\n",
    "                # ^ alternative way:\n",
    "                #     EPSILON = 1e-6\n",
    "                #     p = torch.clamp(p, min=EPSILON, max=1-EPSILON)\n",
    "                #     minus_p = torch.clamp(minus_p, min=EPSILON, max=1-EPSILON)\n",
    "                #     return -p * torch.log(p) - minus_p * torch.log(minus_p)\n",
    "\n",
    "                process_node((nodeIndex * 2) + 1, 1-p)\n",
    "                process_node((nodeIndex * 2) + 2, p)\n",
    "\n",
    "            process_node(\n",
    "                nodeIndex=0,\n",
    "                p_in = torch.ones((nBatch), dtype=torch.float, requires_grad=True)\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            def process_node(depth, nodeIndices):\n",
    "                if depth >= self.depth:\n",
    "                    return\n",
    "                \n",
    "                nonlocal y\n",
    "                # Project x onto the current node's INPUT basis vector\n",
    "                #   Î» = x DOT currNode.X\n",
    "                # (nBatch, nIn) (nBatch, nIn) -> nBatch\n",
    "                Î» = torch.einsum('bi, bi -> b', x, self.X[nodeIndices])\n",
    "\n",
    "                # Project this contribution into OUTPUT space:\n",
    "                #   y += Î» currNode.Y\n",
    "                # nBatch, (nBatch, nOut) -> (nBatch, nOut)\n",
    "                y = y + torch.einsum('n, nj -> nj', Î», self.Y[nodeIndices])\n",
    "\n",
    "                # We'll branch right if x is \"sunny-side\" of the\n",
    "                # hyperplane defined by node.x (else left)\n",
    "                branch_choices = (Î» > 0).long()  # 1 if Î» > 0, else 0, so -ve Î» => LEFT, +ve Î» => RIGHT\n",
    "\n",
    "                # figure out index of node in next layer to visit\n",
    "                process_node(\n",
    "                    depth+1,\n",
    "                    nodeIndices=(nodeIndices * 2) + 1 + branch_choices\n",
    "                )\n",
    "\n",
    "            process_node(\n",
    "                depth=0,\n",
    "                nodeIndices=torch.zeros(nBatch, dtype=torch.int, device=x.device)\n",
    "            )\n",
    "\n",
    "        self.loss = loss / nNodes\n",
    "\n",
    "        return y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FFF({self.X.shape[-1]}, {self.Y.shape[-1]}, depth={self.depth})\"\n",
    "\n",
    "\n",
    "# sanity check\n",
    "\n",
    "fff = FFF(nIn=10, nOut=10, depth=2)\n",
    "nBatch = 2\n",
    "\n",
    "print('Testing training:')\n",
    "x = torch.randn((nBatch, 10), requires_grad=True)\n",
    "y = fff(x)\n",
    "print('loss:', fff.loss)\n",
    "cost = torch.norm(y)\n",
    "cost.backward()\n",
    "print('x.grad:', x.grad)\n",
    "\n",
    "print('Testing inference:')\n",
    "x = torch.randn((nBatch, 10), requires_grad=False)\n",
    "y = fff(x)\n",
    "print('loss:', fff.loss)\n",
    "print('y:', y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§ª Test it out on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [02:01<18:12, 121.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Accuracy of the network over test images: 50.190 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [03:59<15:56, 119.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Accuracy of the network over test images: 51.080 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [05:59<13:57, 119.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Accuracy of the network over test images: 45.970 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [07:58<11:55, 119.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Accuracy of the network over test images: 40.900 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [08:16<12:25, 124.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m# Calculate orthogonality loss for each PiSlice layer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m# loss1 = orthogonality_loss(self.fc1.X) + orthogonality_loss(self.fc1.Y)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39m# loss2 = orthogonality_loss(self.fc2.X) + orthogonality_loss(self.fc2.Y)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39m# return loss1 + loss2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m0.01\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1\u001b[39m.\u001b[39mloss \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2\u001b[39m.\u001b[39mloss)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m train_and_test(Net(), load_MNIST)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# train_and_test(Net(), ortho=True)\u001b[39;00m\n",
      "\u001b[1;32m/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(net, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mloss()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X30sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/code/m2/fff/FFF/.venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/code/m2/fff/FFF/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DEPTH = 8\n",
    "\n",
    "# Neural network architecture\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = FFF(nIn=28*28, nOut=500, depth=DEPTH)\n",
    "        self.fc2 = FFF(nIn=500, nOut=10, depth=DEPTH)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        y_hat = self.fc2(torch.relu(self.fc1(x)))\n",
    "        # y_hat = self.fc2(self.fc1(x))\n",
    "        return y_hat\n",
    "    def loss(self):\n",
    "        # Calculate orthogonality loss for each PiSlice layer\n",
    "        # loss1 = orthogonality_loss(self.fc1.X) + orthogonality_loss(self.fc1.Y)\n",
    "        # loss2 = orthogonality_loss(self.fc2.X) + orthogonality_loss(self.fc2.Y)\n",
    "        # return loss1 + loss2\n",
    "        return 0.01 * (self.fc1.loss + self.fc2.loss)\n",
    "\n",
    "train_and_test(Net(), load_MNIST)\n",
    "# train_and_test(Net(), ortho=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§ª Test it out on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "class Net_regular(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(relu(self.conv1(x)))\n",
    "        x = self.pool(relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = relu(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class Net_FFF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = FFF(nIn=16 * 5 * 5, nOut=120)\n",
    "        self.fc2 = FFF(nIn=120, nOut=84)\n",
    "        self.fc3 = FFF(nIn=84, nOut=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(relu(self.conv1(x)))\n",
    "        x = self.pool(relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = relu(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [00:53<08:03, 53.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Accuracy of the network over test images: 44.140 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [01:47<07:08, 53.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Accuracy of the network over test images: 48.360 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [02:17<09:09, 68.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# net = Net_regular()\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_and_test(Net_regular(), dataloader\u001b[39m=\u001b[39;49mload_CIFAR10)\n",
      "\u001b[1;32m/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(net, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/code/m2/fff/FFF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/m2/fff/FFF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(relu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(relu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pi/code/m2/fff/FFF/experiments/2023-12-01--train_full_tree.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, start_dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/code/m2/fff/FFF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/code/m2/fff/FFF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/m2/fff/FFF/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/code/m2/fff/FFF/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# net = Net_regular()\n",
    "train_and_test(Net_regular(), dataloader=load_CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Accuracy of the network over test images: 12.010 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_test(Net_FFF(), dataloader=load_CIFAR10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
