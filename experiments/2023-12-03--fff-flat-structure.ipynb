{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat structure for X projections\n",
    "\n",
    "I calculated all the lambdas in parallel. This lambdas now represent value function which are only approximations of the true lambda values.\n",
    "The main advantage is that the values can be calculated in parallel. This is equivalent as calculating lambdas for the whole tree in parallel.\n",
    "\n",
    "The approximation between Value functions and lambdas is now done with Y projections.\n",
    "The Y projections take Value functions, and approximate lambda values that are then used for Y projections. Since this is linear operations they can be combined into single matrix Y projection.\n",
    "\n",
    "### Results\n",
    "- There is no degradation in quality for CIFAR10\n",
    "- Network uses half memory bandwidth\n",
    "- Network is 2x-3x faster\n",
    "\n",
    "## Future work\n",
    "- Check if having tree like structure for Y projections gives any advantage over flat structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from math import floor, log2, sqrt\n",
    "\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_STRAT = 'hyperspherical-shell'\n",
    "\n",
    "\n",
    "class FFF(nn.Module):\n",
    "    def __init__(self, nIn: int, nOut: int, depth: Optional[int] = None):\n",
    "        super().__init__()\n",
    "        self.depth = depth or int(floor(log2(nIn)))  # depth is the number of decision boundaries\n",
    "        nNodes = 2 ** self.depth - 1\n",
    "\n",
    "        # each node \"holds\" a basis-vector in INPUT space (.X) and in OUTPUT space (.Y)\n",
    "\n",
    "        if INIT_STRAT == 'gaussian':\n",
    "            # This from orig authors; scaling looks off for self.Y\n",
    "            def create_basis_vectors_of(length, scaling):\n",
    "                return nn.Parameter(torch.empty(nNodes, length).uniform_(-scaling, scaling))\n",
    "            self.X = create_basis_vectors_of(length=nIn, scaling=1/sqrt(nIn))\n",
    "            self.Y = create_basis_vectors_of(length=nOut, scaling=1/sqrt(self.depth + 1))\n",
    "\n",
    "        elif INIT_STRAT == 'hyperspherical-shell':\n",
    "            # Initialize vectors on INPUT/OUTPUT space unit hypersphere\n",
    "            #   (idea: basis vectors should be of unit length).\n",
    "            def create_random_unit_vectors_of(length):\n",
    "                weights = torch.randn(nNodes, length)  # Initialize weights randomly\n",
    "                weights = F.normalize(weights, p=2, dim=-1)  # L2-Normalize along the last dimension\n",
    "                return nn.Parameter(weights)\n",
    "            self.X = create_random_unit_vectors_of(length=nIn)\n",
    "            self.Y = create_random_unit_vectors_of(length=nOut)\n",
    "\n",
    "    def push_away_loss(self, x: torch.Tensor):\n",
    "        return torch.pow((1 - torch.abs(x)), 2).sum()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        nBatch, nIn, nOut = x.shape[0], self.X.shape[-1], self.Y.shape[-1]\n",
    "\n",
    "        current_node = torch.zeros(nBatch, dtype=torch.long, device=x.device)\n",
    "\n",
    "        # Walk the tree, assembling y piecemeal\n",
    "        y = torch.zeros((nBatch, nOut), dtype=torch.float, device=x.device)\n",
    "        for depth in range(self.depth):\n",
    "            # Project x onto the current node's INPUT basis vector\n",
    "            #   λ = x DOT currNode.X\n",
    "            # (nBatch, nIn,) (nBatch, nIn) -> (nBatch,)\n",
    "            λ = torch.einsum(\"b i, b i -> b\", x, self.X[current_node])\n",
    "\n",
    "            y += torch.einsum(\"b, b j -> b j\", λ, self.Y[current_node])\n",
    "\n",
    "            branch_choice = (λ > 0.0).long()\n",
    "            current_node = (current_node * 2) + 1 + branch_choice\n",
    "        return y\n",
    "\n",
    "class FFF_v2(nn.Module):\n",
    "    def __init__(self, nIn: int, nOut: int, depth: Optional[int] = None):\n",
    "        super().__init__()\n",
    "        self.depth = depth or int(floor(log2(nIn)))  # depth is the number of decision boundaries\n",
    "        nNodes = 2 ** self.depth - 1\n",
    "\n",
    "        def create_random_unit_vectors_of(length):\n",
    "            weights = torch.randn(nNodes, length)  # Initialize weights randomly\n",
    "            weights = F.normalize(weights, p=2, dim=-1)  # L2-Normalize along the last dimension\n",
    "            return nn.Parameter(weights)\n",
    "\n",
    "        self.X = nn.Linear(nIn, self.depth, bias=False)\n",
    "        self.Y = create_random_unit_vectors_of(length=nOut)\n",
    "\n",
    "    def forward_old_code(self, x: torch.Tensor):\n",
    "        nBatch, nOut = x.shape[0], self.Y.shape[-1]\n",
    "        current_node = torch.zeros(nBatch, dtype=torch.long, device=x.device)\n",
    "        y = torch.zeros((nBatch, nOut), dtype=torch.float, device=x.device)\n",
    "\n",
    "        λ = self.X(x)\n",
    "        for i in range(self.depth):\n",
    "            y += torch.einsum(\"b, b j -> b j\", λ[:, i], self.Y[current_node])\n",
    "            branch_choice = (λ[:,i] > 0).long()\n",
    "            current_node = (current_node * 2) + 1 + branch_choice\n",
    "        return y\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        nBatch, nOut = x.shape[0], self.Y.shape[-1]\n",
    "\n",
    "        λ = self.X(x)\n",
    "        branch_choice = (λ > 0).long()\n",
    "\n",
    "        indenes = torch.empty((nBatch, self.depth), dtype=torch.long, device=x.device)\n",
    "        current_node = torch.zeros(nBatch, dtype=torch.long, device=x.device)\n",
    "        for i in range(self.depth):\n",
    "            indenes[:, i] = current_node\n",
    "            current_node = (current_node * 2) + 1 + branch_choice[:, i]\n",
    "\n",
    "        y = torch.einsum(\"b i, b i j -> b j\", λ, self.Y[indenes])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_FFF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = FFF(16 * 5 * 5, 120, depth=None)\n",
    "        self.fc2 = FFF(120, 84, depth=None)\n",
    "        self.fc3 = FFF(84, 10, depth=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        train_key = False\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x= F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class Net_FFF_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = FFF_v2(16 * 5 * 5, 120, depth=None)\n",
    "        self.fc2 = FFF_v2(120, 84, depth=None)\n",
    "        self.fc3 = FFF_v2(84, 10, depth=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        train_key = False\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x= F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net: nn.Module, data_loader: torch.utils.data.DataLoader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def train(net: nn.Module,\n",
    "          trainloader: torch.utils.data.DataLoader,\n",
    "          testloader: torch.utils.data.DataLoader,\n",
    "          epochs: int):\n",
    "\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch} loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for = 40\n",
    "\n",
    "net_FFF = Net_FFF().to(device)\n",
    "net_FFF_v2 = Net_FFF_v2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 2.0214164122901\n",
      "Epoch 1 loss: 1.6917507355780248\n",
      "Epoch 2 loss: 1.5582671805720805\n",
      "Epoch 3 loss: 1.466966018347484\n",
      "Epoch 4 loss: 1.397243906469906\n",
      "Epoch 5 loss: 1.342637888001054\n",
      "Epoch 6 loss: 1.2993970338036032\n",
      "Epoch 7 loss: 1.2574183681736821\n",
      "Epoch 8 loss: 1.224845184237146\n",
      "Epoch 9 loss: 1.1952471472418216\n",
      "Epoch 10 loss: 1.167301650699752\n",
      "Epoch 11 loss: 1.1404021249707703\n",
      "Epoch 12 loss: 1.122293352928308\n",
      "Epoch 13 loss: 1.0975981932466903\n",
      "Epoch 14 loss: 1.081290222647245\n",
      "Epoch 15 loss: 1.0580935062045027\n",
      "Epoch 16 loss: 1.0382005909214849\n",
      "Epoch 17 loss: 1.0193680747390708\n",
      "Epoch 18 loss: 1.003220223862192\n",
      "Epoch 19 loss: 0.989182462777628\n",
      "Epoch 20 loss: 0.9743737374120356\n",
      "Epoch 21 loss: 0.9651489597757149\n",
      "Epoch 22 loss: 0.9503091465481712\n",
      "Epoch 23 loss: 0.9410525194519316\n",
      "Epoch 24 loss: 0.9349830432621109\n",
      "Epoch 25 loss: 0.9194280529571006\n",
      "Epoch 26 loss: 0.9148033989969727\n",
      "Epoch 27 loss: 0.9084660581615575\n",
      "Epoch 28 loss: 0.8975272242675352\n",
      "Epoch 29 loss: 0.8923117654097964\n",
      "Epoch 30 loss: 0.8796971001283592\n",
      "Epoch 31 loss: 0.8733983437728394\n",
      "Epoch 32 loss: 0.8626622697886299\n",
      "Epoch 33 loss: 0.8514948269290388\n",
      "Epoch 34 loss: 0.8457118805564577\n",
      "Epoch 35 loss: 0.8379777692772848\n",
      "Epoch 36 loss: 0.8410189993241254\n",
      "Epoch 37 loss: 0.8257805339210783\n",
      "Epoch 38 loss: 0.8152334441614273\n",
      "Epoch 39 loss: 0.8032897168108265\n"
     ]
    }
   ],
   "source": [
    "train(net_FFF, trainloader, testloader, train_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 2.049093236398819\n",
      "Epoch 1 loss: 1.7930712974284921\n",
      "Epoch 2 loss: 1.6349740842419207\n",
      "Epoch 3 loss: 1.5265829590580346\n",
      "Epoch 4 loss: 1.448452637018755\n",
      "Epoch 5 loss: 1.3829183194338512\n",
      "Epoch 6 loss: 1.3330699976752787\n",
      "Epoch 7 loss: 1.290956637743489\n",
      "Epoch 8 loss: 1.2561685651769419\n",
      "Epoch 9 loss: 1.2253639742236613\n",
      "Epoch 10 loss: 1.20175103534518\n",
      "Epoch 11 loss: 1.180387809453413\n",
      "Epoch 12 loss: 1.161542066680196\n",
      "Epoch 13 loss: 1.144530805023125\n",
      "Epoch 14 loss: 1.131169364885296\n",
      "Epoch 15 loss: 1.11852028668689\n",
      "Epoch 16 loss: 1.105437661375841\n",
      "Epoch 17 loss: 1.0944929507077503\n",
      "Epoch 18 loss: 1.0825332180618326\n",
      "Epoch 19 loss: 1.073117415465967\n",
      "Epoch 20 loss: 1.0629768208469577\n",
      "Epoch 21 loss: 1.0559150125364514\n",
      "Epoch 22 loss: 1.0503833335074013\n",
      "Epoch 23 loss: 1.0432353771251182\n",
      "Epoch 24 loss: 1.0371619969072854\n",
      "Epoch 25 loss: 1.033444506737887\n",
      "Epoch 26 loss: 1.0287578622703357\n",
      "Epoch 27 loss: 1.0248553832168774\n",
      "Epoch 28 loss: 1.0205961662485166\n",
      "Epoch 29 loss: 1.016515857423358\n",
      "Epoch 30 loss: 1.0141713905822285\n",
      "Epoch 31 loss: 1.011179256622139\n",
      "Epoch 32 loss: 1.0064240009583476\n",
      "Epoch 33 loss: 1.0007176944971694\n",
      "Epoch 34 loss: 0.9968643949159881\n",
      "Epoch 35 loss: 0.9926899430696922\n",
      "Epoch 36 loss: 0.9868727108401716\n",
      "Epoch 37 loss: 0.9839011804222146\n",
      "Epoch 38 loss: 0.976470815098804\n",
      "Epoch 39 loss: 0.9754179306042469\n"
     ]
    }
   ],
   "source": [
    "train(net_FFF_v2, trainloader, testloader, train_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(54.2500, device='cuda:0'), tensor(60.2300, device='cuda:0'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(net_FFF, testloader), evaluate(net_FFF_v2, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
